{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "\n",
    "text_path = '../data/text/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#读取文件，并为数据设定标签：1:'负面的',0:'正面的'\n",
    "def read_files():\n",
    "    all_label = []\n",
    "    with open(text_path + 'negitive.txt', 'rb') as fp:\n",
    "        all_text = fp.readlines()\n",
    "\n",
    "    all_text_len = len(all_text)\n",
    "    for i in range(len(all_text)):\n",
    "        all_label.append(1)\n",
    "\n",
    "    with open(text_path + 'postive.txt', 'rb') as fp:\n",
    "        all_text += fp.readlines()\n",
    "\n",
    "    for i in range(len(all_text[all_text_len:])):\n",
    "        all_label.append(0)\n",
    "\n",
    "    return all_text, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#建立词典\n",
    "def create_dict():\n",
    "    dict = open(text_path + 'negitive.txt', 'rb').read()\n",
    "    dict += open(text_path + 'postive.txt', 'rb').read()\n",
    "    dict_list = set(list(dict.decode('utf8')))\n",
    "    dicts = {}\n",
    "    for i, d in enumerate(dict_list):\n",
    "        dicts[d] = i\n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将评论的文字转换成序列\n",
    "def create_seq(all_text):\n",
    "    seq_len = []\n",
    "    dicts = create_dict()\n",
    "    sequences = []\n",
    "    for text in all_text:\n",
    "        if text == '\\n':\n",
    "            continue\n",
    "        text = text.strip()\n",
    "        text_list = list(text.decode('utf8'))\n",
    "        sequence = [dicts[char] for char in text_list]\n",
    "        seq_len.append(len(sequence))\n",
    "        sequences.append(sequence)\n",
    "    return sequences, seq_len, dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_model(max_seq, max_features):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_features,#大或等于0的整数，字典长度，即输入数据最大下标+1\n",
    "                        output_dim=128, #大于0的整数，代表全连接嵌入的维度\n",
    "                        input_length=max_seq #当输入序列的长度固定时，该值为其长度。如果要在该层后接Flatten层，然后接Dense层，则必须指定该参数，否则Dense层的输出维度无法自动推断\n",
    "              ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_rnn_model(max_seq, max_features):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_features,#大或等于0的整数，字典长度，即输入数据最大下标+1\n",
    "                        output_dim=128, #大于0的整数，代表全连接嵌入的维度\n",
    "                        input_length=max_seq #当输入序列的长度固定时，该值为其长度。如果要在该层后接Flatten层，然后接Dense层，则必须指定该参数，否则Dense层的输出维度无法自动推断\n",
    "              ))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(SimpleRNN(units=16))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_lstm_model(max_seq, max_features):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_features,#大或等于0的整数，字典长度，即输入数据最大下标+1\n",
    "                        output_dim=128, #大于0的整数，代表全连接嵌入的维度\n",
    "                        input_length=max_seq #当输入序列的长度固定时，该值为其长度。如果要在该层后接Flatten层，然后接Dense层，则必须指定该参数，否则Dense层的输出维度无法自动推断\n",
    "              ))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "max_seq: 250\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 128)          405248    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 16)                2320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 412,177\n",
      "Trainable params: 412,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      "51s - loss: 0.3156 - acc: 0.8501 - val_loss: 0.2667 - val_acc: 0.8986\n",
      "Epoch 2/5\n",
      "50s - loss: 0.1343 - acc: 0.9563 - val_loss: 0.2069 - val_acc: 0.9290\n",
      "Epoch 3/5\n",
      "71s - loss: 0.1047 - acc: 0.9664 - val_loss: 0.1685 - val_acc: 0.9440\n",
      "Epoch 4/5\n",
      "68s - loss: 0.1065 - acc: 0.9644 - val_loss: 0.2382 - val_acc: 0.9249\n",
      "Epoch 5/5\n",
      "66s - loss: 0.0819 - acc: 0.9732 - val_loss: 0.2284 - val_acc: 0.9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8f8f7bcf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text, all_label = read_files()\n",
    "\n",
    "#dicts = create_dict()\n",
    "sequences, seq_len, dicts = create_seq(all_text)\n",
    "\n",
    "print(max(seq_len))\n",
    "max_seq = int(max(seq_len) / 2)\n",
    "print('max_seq:', max_seq)\n",
    "\n",
    "max_features = len(dicts) + 1\n",
    "\n",
    "#固定每个sequences的长度\n",
    "train_data = pad_sequences(sequences, maxlen=max_seq) \n",
    "\n",
    "#model = text_model(max_seq, max_features)\n",
    "model = text_rnn_model(max_seq, max_features)\n",
    "#model = text_lstm_model(max_seq, max_features)\n",
    "\n",
    "'''\n",
    "try:\n",
    "    model.load_weights(\"saveModel/textModel.h5\")\n",
    "    print (\"加载模型成功\")\n",
    "except:\n",
    "    print (\"加载模型失败\")\n",
    "'''    \n",
    "model.fit(train_data, all_label, validation_split=0.2, batch_size=256, epochs=5, verbose=2)\n",
    "\n",
    "#model.save_weights(\"saveModel/textModel.h5\")\n",
    "#print (\"保存成功\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s\n",
      "这个货很好，很流畅 [预测结果: 正面的 ] [Probability: [ 0.00202224] ]\n",
      "\n",
      "这个东西真好吃， [预测结果: 正面的 ] [Probability: [ 0.35236385] ]\n",
      "\n",
      "服务太糟糕,味道差 [预测结果: 负面的 ] [Probability: [ 0.99977666] ]\n",
      "\n",
      "你他妈的是个傻逼 [预测结果: 负面的 ] [Probability: [ 0.87382108] ]\n",
      "\n",
      "这个贴花的款式好看 [预测结果: 正面的 ] [Probability: [ 0.02073266] ]\n",
      "\n",
      "看着不错，生产日期也是新的是16年12月份的，就是有点小贵 [预测结果: 正面的 ] [Probability: [ 0.29493278] ]\n",
      "\n",
      "一股淡淡的腥味.每次喝完都会吃一口白糖 [预测结果: 负面的 ] [Probability: [ 0.75243485] ]\n",
      "\n",
      "还没喝，不过，看着应该不错哟 [预测结果: 正面的 ] [Probability: [ 0.05180429] ]\n",
      "\n",
      "用来看电视还是不错的，就是有些大打字不习惯，要是可以换输入法就好了！ [预测结果: 正面的 ] [Probability: [ 0.02825704] ]\n",
      "\n",
      "嗯，中间出了点小问题已经联系苹果客服解决了，打游戏也没有卡顿，总体来讲还不错吧！ [预测结果: 负面的 ] [Probability: [ 0.5875963] ]\n",
      "\n",
      "下软件下的多的时候死了一回机，强制重启之后就恢复了 [预测结果: 负面的 ] [Probability: [ 0.99715388] ]\n",
      "\n",
      "东西用着还可以很流畅！ [预测结果: 正面的 ] [Probability: [ 0.0041736] ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "test = [\"这个货很好，很流畅\", \"这个东西真好吃，\",\n",
    "        \"服务太糟糕,味道差\", \"你他妈的是个傻逼\",\n",
    "        \"这个贴花的款式好看\",\n",
    "        \"看着不错，生产日期也是新的是16年12月份的，就是有点小贵\",\n",
    "        \"一股淡淡的腥味.每次喝完都会吃一口白糖\",\n",
    "        \"还没喝，不过，看着应该不错哟\",\n",
    "        \"用来看电视还是不错的，就是有些大打字不习惯，要是可以换输入法就好了！\",\n",
    "        \"嗯，中间出了点小问题已经联系苹果客服解决了，打游戏也没有卡顿，总体来讲还不错吧！\",\n",
    "        \"下软件下的多的时候死了一回机，强制重启之后就恢复了\",\n",
    "        \"东西用着还可以很流畅！\"]\n",
    "test_sequences = []\n",
    "for line in test:\n",
    "    l = list(line)\n",
    "    sequence = [dicts[char] for char in l]\n",
    "    test_sequences.append(sequence)\n",
    "\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_seq)\n",
    "\n",
    "predict = model.predict_classes(test_data)\n",
    "#print(predict[:20])\n",
    "#转换为1维矩阵\n",
    "predict_classes = predict.reshape(-1)\n",
    "#print(predict_classes[:20])\n",
    "sentimentDict = {1:'负面的',0:'正面的'}\n",
    "    \n",
    "result = model.predict(test_data)\n",
    "for i, j in enumerate(test):\n",
    "    print(j, '[预测结果:',sentimentDict[predict_classes[i]], ']', '[Probability:', result[i], ']')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
